{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating\n",
    "Instruction 1: Provide an example of concatenating multiple feature extraction methods using\n",
    "your dataset.\n",
    "In many real-world examples, there are many ways to extract features from a dataset. Often it is\n",
    "beneficial to combine several methods to obtain good performance. This example shows how to\n",
    "use FeatureUnion to combine features obtained by PCA and univariate selection. Combining\n",
    "features using this transformer has the benefit that it allows cross validation and grid searches\n",
    "over the whole process. The combination used in this example is not particularly helpful on this\n",
    "dataset and is only used to illustrate the usage of FeatureUnion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# using California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Pipeline(steps=[('features',\n",
      "                 FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
      "                                                ('univ_select',\n",
      "                                                 SelectKBest(k=1))])),\n",
      "                ('svm', SVR(C=10, epsilon=0.2))])\n"
     ]
    }
   ],
   "source": [
    "# Fetch the dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA transformer\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Univariate feature selection transformer\n",
    "selection = SelectKBest(k=1)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X_train, y_train).transform(X_train)\n",
    "\n",
    "svm = SVR()\n",
    "\n",
    "# Do grid search over k (for feature selection), C and epsilon (for SVM):\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "                  features__univ_select__k=[1, 2],\n",
    "                  svm__C=[0.1, 1, 10],\n",
    "                  svm__epsilon=[0.1, 0.2, 0.3])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
